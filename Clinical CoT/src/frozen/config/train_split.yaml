train_75:
  # ModelArguments
  model_name_or_path: path/to/llama2_7B/75%/best/model/checkpoint
  freeze_LM: true
  model_4bit: false
  img_token_num: 2
  img_input_channel: 15
  resnet_depth: 50
  resnet_fc_dim: 2048
  # TrainingArguments
  img_type: parcel 
  wandb_project: MedicalCoT
  wandb_name: rationale_75
  save_dir: pytorch_lightning/checkpoint/save/dir
  devices: [0,1,2,3,4,5,6,7]
  max_epochs: 50
  do_train: true
  do_test: false
  lr: 0.0002
  scheduler_type: ReduceLROnPlateau
  # data
  source_max_len: 1024
  target_max_len: 1024
  predict_with_generate: false
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  strategy: deepspeed_stage_3

train_50:
  # ModelArguments
  model_name_or_path: path/to/llama2_7B/50%/best/model/checkpoint
  freeze_LM: true
  model_4bit: false
  img_token_num: 2
  img_input_channel: 15
  resnet_depth: 50
  resnet_fc_dim: 2048
  # TrainingArguments
  img_type: parcel 
  wandb_project: MedicalCoT
  wandb_name: rationale_50
  save_dir: pytorch_lightning/checkpoint/save/dir
  devices: [0,1,2,3,4,5,6,7]
  max_epochs: 50
  do_train: true
  do_test: false
  lr: 0.0002
  scheduler_type: ReduceLROnPlateau
  # data
  source_max_len: 1024
  target_max_len: 1024
  predict_with_generate: false
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  strategy: deepspeed_stage_3

train_25:
  # ModelArguments
  model_name_or_path: path/to/llama2_7B/25%/best/model/checkpoint
  freeze_LM: true
  model_4bit: false
  img_token_num: 2
  img_input_channel: 15
  resnet_depth: 50
  resnet_fc_dim: 2048
  # TrainingArguments
  img_type: parcel 
  wandb_project: MedicalCoT
  wandb_name: rationale_25
  save_dir: pytorch_lightning/checkpoint/save/dir
  devices: [0,1,2,3,4,5,6,7]
  max_epochs: 50
  do_train: true
  do_test: false
  lr: 0.0002
  scheduler_type: ReduceLROnPlateau
  # data
  source_max_len: 1024
  target_max_len: 1024
  predict_with_generate: false
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  strategy: deepspeed_stage_3

train_75_wo_rationale:
  # ModelArguments
  model_name_or_path: path/to/llama2_7B/wo/rationale/75%/best/model/checkpoint
  freeze_LM: true
  model_4bit: false
  img_token_num: 2
  img_input_channel: 15
  resnet_depth: 50
  resnet_fc_dim: 2048
  # TrainingArguments
  img_type: parcel
  wandb_project: MedicalCoT
  wandb_name: wo_rationale_75
  save_dir: pytorch_lightning/checkpoint/save/dir
  devices: [0,1,2,3,4,5,6,7]
  max_epochs: 50
  do_train: true
  do_test: false
  lr: 0.00005
  scheduler_type: ReduceLROnPlateau
  strategy: deepspeed_stage_3
  # data
  source_max_len: 1024
  target_max_len: 1024
  predict_with_generate: false
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1

train_50_wo_rationale:
  # ModelArguments
  model_name_or_path: path/to/llama2_7B/wo/rationale/50%/best/model/checkpoint
  freeze_LM: true
  model_4bit: false
  img_token_num: 2
  img_input_channel: 15
  resnet_depth: 50
  resnet_fc_dim: 2048
  # TrainingArguments
  img_type: parcel
  wandb_project: MedicalCoT
  wandb_name: wo_rationale_50
  save_dir: pytorch_lightning/checkpoint/save/dir
  devices: [0,1,2,3,4,5,6,7]
  max_epochs: 50
  do_train: true
  do_test: false
  lr: 0.00005
  scheduler_type: ReduceLROnPlateau
  strategy: deepspeed_stage_3
  # data
  source_max_len: 1024
  target_max_len: 1024
  predict_with_generate: false
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1

train_25_wo_rationale:
  # ModelArguments
  model_name_or_path: path/to/llama2_7B/wo/rationale/25%/best/model/checkpoint
  freeze_LM: true
  model_4bit: false
  img_token_num: 2
  img_input_channel: 15
  resnet_depth: 50
  resnet_fc_dim: 2048
  # TrainingArguments
  img_type: parcel
  wandb_project: MedicalCoT
  wandb_name: wo_rationale_25
  save_dir: pytorch_lightning/checkpoint/save/dir
  devices: [0,1,2,3,4,5,6,7]
  max_epochs: 50
  do_train: true
  do_test: false
  lr: 0.00005
  scheduler_type: ReduceLROnPlateau
  strategy: deepspeed_stage_3
  # data
  source_max_len: 1024
  target_max_len: 1024
  predict_with_generate: false
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1

